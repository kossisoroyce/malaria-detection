{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# YOLOv8 Malaria Detection - Colab Pro Optimized\n",
    "## Clinical Parasite Detection Training Pipeline\n",
    "\n",
    "**Optimized for Colab Pro V100/A100 GPUs**\n",
    "- Enhanced batch sizes and full training cycles\n",
    "- Advanced contour detection for bounding boxes\n",
    "- Production-ready model export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU and install dependencies\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"🚀 CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"🎯 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install ultralytics kagglehub wandb opencv-python matplotlib seaborn scikit-learn -q\n",
    "print(\"✅ All packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os, shutil, random, cv2, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import kagglehub, yaml, time, zipfile\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "# Set seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "print(\"📚 Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Colab Pro Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab Pro optimized settings\n",
    "CONFIG = {\n",
    "    'epochs': 100, 'batch_size': 32, 'image_size': 640, 'workers': 8,\n",
    "    'lr0': 0.01, 'weight_decay': 0.0005, 'patience': 25,\n",
    "    'optimizer': 'AdamW', 'cache': 'ram'\n",
    "}\n",
    "\n",
    "print(f\"⚙️ Batch: {CONFIG['batch_size']}, Epochs: {CONFIG['epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Download & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Kaggle dataset\n",
    "print(\"📥 Downloading dataset...\")\n",
    "kaggle_path = kagglehub.dataset_download(\"iarunava/cell-images-for-detecting-malaria\")\n",
    "print(f\"✅ Downloaded to: {kaggle_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bbox(image_path, padding=0.15):\n",
    "    \"\"\"Enhanced bounding box generation with CLAHE preprocessing.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return (0.5, 0.5, 0.85, 0.85)\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # CLAHE enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)\n",
    "    \n",
    "    # Adaptive threshold\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Filter by area\n",
    "        min_area = (w * h) * 0.01\n",
    "        valid_contours = [c for c in contours if cv2.contourArea(c) > min_area]\n",
    "        \n",
    "        if valid_contours:\n",
    "            largest = max(valid_contours, key=cv2.contourArea)\n",
    "            x, y, bbox_w, bbox_h = cv2.boundingRect(largest)\n",
    "            \n",
    "            # Add padding\n",
    "            pad_x, pad_y = int(bbox_w * padding), int(bbox_h * padding)\n",
    "            x = max(0, x - pad_x)\n",
    "            y = max(0, y - pad_y)\n",
    "            bbox_w = min(w - x, bbox_w + 2 * pad_x)\n",
    "            bbox_h = min(h - y, bbox_h + 2 * pad_y)\n",
    "            \n",
    "            # YOLO format\n",
    "            center_x = (x + bbox_w / 2) / w\n",
    "            center_y = (y + bbox_h / 2) / h\n",
    "            norm_w = bbox_w / w\n",
    "            norm_h = bbox_h / h\n",
    "            \n",
    "            return (max(0.1, min(0.9, center_x)), max(0.1, min(0.9, center_y)), \n",
    "                   max(0.1, min(0.8, norm_w)), max(0.1, min(0.8, norm_h)))\n",
    "    \n",
    "    return (0.5, 0.5, 0.85, 0.85)\n",
    "\n",
    "print(\"🔧 Bbox generation function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YOLO dataset structure\n",
    "yolo_path = Path(\"yolo_malaria_pro\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (yolo_path / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (yolo_path / split / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"📁 Created structure: {yolo_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and process dataset\n",
    "kaggle_path = Path(kaggle_path)\n",
    "cell_images_path = None\n",
    "\n",
    "for root, dirs, files in os.walk(kaggle_path):\n",
    "    if 'Parasitized' in dirs and 'Uninfected' in dirs:\n",
    "        cell_images_path = Path(root)\n",
    "        break\n",
    "\n",
    "print(f\"📊 Found images at: {cell_images_path}\")\n",
    "\n",
    "# Process classes\n",
    "all_files = []\n",
    "for class_name in ['Parasitized', 'Uninfected']:\n",
    "    class_path = cell_images_path / class_name\n",
    "    class_files = list(class_path.glob('*.png'))\n",
    "    print(f\"   {class_name}: {len(class_files)} images\")\n",
    "    \n",
    "    class_id = 0 if class_name == 'Parasitized' else None\n",
    "    for img_path in class_files:\n",
    "        all_files.append((img_path, class_id))\n",
    "\n",
    "# Split dataset\n",
    "random.shuffle(all_files)\n",
    "total = len(all_files)\n",
    "train_end = int(total * 0.70)\n",
    "val_end = int(total * 0.90)\n",
    "\n",
    "splits = {\n",
    "    'train': all_files[:train_end],\n",
    "    'val': all_files[train_end:val_end],\n",
    "    'test': all_files[val_end:]\n",
    "}\n",
    "\n",
    "print(f\"📈 Split: Train={len(splits['train'])}, Val={len(splits['val'])}, Test={len(splits['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert files to YOLO format\n",
    "for split_name, files in splits.items():\n",
    "    print(f\"🔄 Processing {split_name}...\")\n",
    "    \n",
    "    images_dir = yolo_path / split_name / \"images\"\n",
    "    labels_dir = yolo_path / split_name / \"labels\"\n",
    "    \n",
    "    for i, (img_path, class_id) in enumerate(files):\n",
    "        if i % 2000 == 0 and i > 0:\n",
    "            print(f\"   Progress: {i}/{len(files)}\")\n",
    "        \n",
    "        # Copy image\n",
    "        new_name = f\"{split_name}_{i:06d}.png\"\n",
    "        shutil.copy2(img_path, images_dir / new_name)\n",
    "        \n",
    "        # Create label\n",
    "        label_path = labels_dir / f\"{split_name}_{i:06d}.txt\"\n",
    "        if class_id is not None:\n",
    "            bbox = generate_bbox(str(img_path))\n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write(f\"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n",
    "        else:\n",
    "            label_path.touch()\n",
    "    \n",
    "    print(f\"✅ {split_name} complete\")\n",
    "\n",
    "print(\"🎉 Dataset conversion complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml\n",
    "yaml_content = f\"\"\"path: {yolo_path.absolute()}\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['malaria_parasite']\n",
    "\n",
    "# Stats\n",
    "total_images: {total}\n",
    "converted_on: {datetime.now().isoformat()}\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = yolo_path / \"malaria_data.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"📄 Config created: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples with bounding boxes\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "train_images = list((yolo_path / \"train\" / \"images\").glob(\"*.png\"))\n",
    "samples = random.sample(train_images, 6)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, img_path in enumerate(samples):\n",
    "    image = Image.open(img_path)\n",
    "    w, h = image.size\n",
    "    \n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"Sample {i+1}\")\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Load label\n",
    "    label_path = yolo_path / \"train\" / \"labels\" / f\"{img_path.stem}.txt\"\n",
    "    if label_path.exists() and label_path.stat().st_size > 0:\n",
    "        with open(label_path, 'r') as f:\n",
    "            line = f.readline().strip()\n",
    "            if line:\n",
    "                parts = line.split()\n",
    "                center_x, center_y, width, height = map(float, parts[1:5])\n",
    "                \n",
    "                x = (center_x - width/2) * w\n",
    "                y = (center_y - height/2) * h\n",
    "                box_w = width * w\n",
    "                box_h = height * h\n",
    "                \n",
    "                rect = patches.Rectangle((x, y), box_w, box_h, \n",
    "                                       linewidth=2, edgecolor='red', facecolor='none')\n",
    "                axes[i].add_patch(rect)\n",
    "                axes[i].text(x, y-5, 'Parasite', color='red', fontsize=10, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"📊 Sample visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize & Train YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = YOLO('yolov8n.pt')\n",
    "print(f\"📦 Model: {sum(p.numel() for p in model.model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "train_args = {\n",
    "    'data': str(yaml_path),\n",
    "    'epochs': CONFIG['epochs'],\n",
    "    'batch': CONFIG['batch_size'],\n",
    "    'imgsz': CONFIG['image_size'],\n",
    "    'workers': CONFIG['workers'],\n",
    "    'cache': CONFIG['cache'],\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "    'lr0': CONFIG['lr0'],\n",
    "    'weight_decay': CONFIG['weight_decay'],\n",
    "    'patience': CONFIG['patience'],\n",
    "    'optimizer': CONFIG['optimizer'],\n",
    "    'cos_lr': True,\n",
    "    'amp': True,\n",
    "    'project': 'malaria_detection_pro',\n",
    "    'name': 'yolov8n_colab_pro',\n",
    "    'exist_ok': True,\n",
    "    'plots': True,\n",
    "    'save_period': 10\n",
    "}\n",
    "\n",
    "print(\"⚙️ Training config ready\")\n",
    "for key in ['epochs', 'batch', 'lr0', 'optimizer']:\n",
    "    print(f\"   {key}: {train_args[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(f\"🏁 Training started at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = model.train(**train_args)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"🏆 Training completed in {training_time/3600:.1f} hours\")\n",
    "print(f\"💾 Best model: {model.trainer.best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate & Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "best_model = YOLO(model.trainer.best)\n",
    "test_results = best_model.val(data=str(yaml_path), split='test')\n",
    "\n",
    "print(\"🎯 Test Results:\")\n",
    "print(f\"   mAP50: {test_results.box.map50:.4f}\")\n",
    "print(f\"   mAP50-95: {test_results.box.map:.4f}\")\n",
    "print(f\"   Precision: {test_results.box.mp:.4f}\")\n",
    "print(f\"   Recall: {test_results.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export models\n",
    "print(\"📦 Exporting models...\")\n",
    "\n",
    "exports = {}\n",
    "try:\n",
    "    onnx_path = best_model.export(format='onnx', optimize=True)\n",
    "    exports['onnx'] = onnx_path\n",
    "    print(f\"✅ ONNX: {onnx_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ONNX failed: {e}\")\n",
    "\n",
    "try:\n",
    "    torchscript_path = best_model.export(format='torchscript')\n",
    "    exports['torchscript'] = torchscript_path\n",
    "    print(f\"✅ TorchScript: {torchscript_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ TorchScript failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Inference & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on samples\n",
    "test_images = list((yolo_path / \"test\" / \"images\").glob(\"*.png\"))[:6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, img_path in enumerate(test_images):\n",
    "    # Run inference\n",
    "    results = best_model(str(img_path))\n",
    "    \n",
    "    # Load and process image\n",
    "    image = cv2.imread(str(img_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw predictions\n",
    "    if len(results[0].boxes) > 0:\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "        confs = results[0].boxes.conf.cpu().numpy()\n",
    "        \n",
    "        for box, conf in zip(boxes, confs):\n",
    "            x1, y1, x2, y2 = box.astype(int)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(image, f'Parasite {conf:.2f}', (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f\"Test {i+1} - {len(results[0].boxes)} detections\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"🔍 Inference testing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Results Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create downloadable results package\n",
    "zip_name = f\"malaria_detection_pro_{datetime.now().strftime('%Y%m%d_%H%M')}.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Add models\n",
    "    zipf.write(model.trainer.best, 'models/best_model.pt')\n",
    "    \n",
    "    for format_name, path in exports.items():\n",
    "        if path and os.path.exists(path):\n",
    "            zipf.write(path, f'models/best_model.{format_name}')\n",
    "    \n",
    "    # Add config\n",
    "    zipf.write(yaml_path, 'config/malaria_data.yaml')\n",
    "    \n",
    "    # Add training results\n",
    "    results_dir = Path(model.trainer.save_dir)\n",
    "    for file in results_dir.glob('*.png'):\n",
    "        zipf.write(file, f'results/{file.name}')\n",
    "    \n",
    "    if (results_dir / 'results.csv').exists():\n",
    "        zipf.write(results_dir / 'results.csv', 'results/training_metrics.csv')\n",
    "    \n",
    "    # Add summary\n",
    "    summary = f\"\"\"# Malaria Detection Results - Colab Pro\n",
    "\n",
    "## Performance\n",
    "- mAP50: {test_results.box.map50:.4f}\n",
    "- mAP50-95: {test_results.box.map:.4f}\n",
    "- Precision: {test_results.box.mp:.4f}\n",
    "- Recall: {test_results.box.mr:.4f}\n",
    "\n",
    "## Configuration\n",
    "- Model: YOLOv8n\n",
    "- Epochs: {CONFIG['epochs']}\n",
    "- Batch: {CONFIG['batch_size']}\n",
    "- Optimizer: {CONFIG['optimizer']}\n",
    "\n",
    "Generated: {datetime.now().isoformat()}\n",
    "\"\"\"\n",
    "    zipf.writestr('README.md', summary)\n",
    "\n",
    "print(f\"📦 Results package: {zip_name}\")\n",
    "print(f\"📊 Final mAP50: {test_results.box.map50:.4f}\")\n",
    "print(\"🎉 Training pipeline complete!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
